{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99b2a9b-7278-4d31-91ba-9d045d1000ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train: 0\n",
      "Missing values in test: 0\n",
      "\n",
      "Train data description:\n",
      "                 id  Gender           Age        Height        Weight  \\\n",
      "count   20758.00000   20758  20758.000000  20758.000000  20758.000000   \n",
      "unique          NaN       2           NaN           NaN           NaN   \n",
      "top             NaN  Female           NaN           NaN           NaN   \n",
      "freq            NaN   10422           NaN           NaN           NaN   \n",
      "mean    10378.50000     NaN     23.841804      1.700245     87.887768   \n",
      "std      5992.46278     NaN      5.688072      0.087312     26.379443   \n",
      "min         0.00000     NaN     14.000000      1.450000     39.000000   \n",
      "25%      5189.25000     NaN     20.000000      1.631856     66.000000   \n",
      "50%     10378.50000     NaN     22.815416      1.700000     84.064875   \n",
      "75%     15567.75000     NaN     26.000000      1.762887    111.600553   \n",
      "max     20757.00000     NaN     61.000000      1.975663    165.057269   \n",
      "\n",
      "       family_history_with_overweight   FAVC          FCVC           NCP  \\\n",
      "count                           20758  20758  20758.000000  20758.000000   \n",
      "unique                              2      2           NaN           NaN   \n",
      "top                               yes    yes           NaN           NaN   \n",
      "freq                            17014  18982           NaN           NaN   \n",
      "mean                              NaN    NaN      2.445908      2.761332   \n",
      "std                               NaN    NaN      0.533218      0.705375   \n",
      "min                               NaN    NaN      1.000000      1.000000   \n",
      "25%                               NaN    NaN      2.000000      3.000000   \n",
      "50%                               NaN    NaN      2.393837      3.000000   \n",
      "75%                               NaN    NaN      3.000000      3.000000   \n",
      "max                               NaN    NaN      3.000000      4.000000   \n",
      "\n",
      "             CAEC  SMOKE          CH2O    SCC           FAF           TUE  \\\n",
      "count       20758  20758  20758.000000  20758  20758.000000  20758.000000   \n",
      "unique          4      2           NaN      2           NaN           NaN   \n",
      "top     Sometimes     no           NaN     no           NaN           NaN   \n",
      "freq        17529  20513           NaN  20071           NaN           NaN   \n",
      "mean          NaN    NaN      2.029418    NaN      0.981747      0.616756   \n",
      "std           NaN    NaN      0.608467    NaN      0.838302      0.602113   \n",
      "min           NaN    NaN      1.000000    NaN      0.000000      0.000000   \n",
      "25%           NaN    NaN      1.792022    NaN      0.008013      0.000000   \n",
      "50%           NaN    NaN      2.000000    NaN      1.000000      0.573887   \n",
      "75%           NaN    NaN      2.549617    NaN      1.587406      1.000000   \n",
      "max           NaN    NaN      3.000000    NaN      3.000000      2.000000   \n",
      "\n",
      "             CALC                 MTRANS        NObeyesdad  \n",
      "count       20758                  20758             20758  \n",
      "unique          3                      5                 7  \n",
      "top     Sometimes  Public_Transportation  Obesity_Type_III  \n",
      "freq        15066                  16687              4046  \n",
      "mean          NaN                    NaN               NaN  \n",
      "std           NaN                    NaN               NaN  \n",
      "min           NaN                    NaN               NaN  \n",
      "25%           NaN                    NaN               NaN  \n",
      "50%           NaN                    NaN               NaN  \n",
      "75%           NaN                    NaN               NaN  \n",
      "max           NaN                    NaN               NaN  \n",
      "\n",
      "=== LogisticRegression ===\n",
      "Cross-validated Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.88      0.94      0.91      2018\n",
      "      Normal_Weight       0.85      0.81      0.83      2465\n",
      "     Obesity_Type_I       0.82      0.82      0.82      2328\n",
      "    Obesity_Type_II       0.93      0.96      0.95      2598\n",
      "   Obesity_Type_III       0.99      1.00      0.99      3237\n",
      " Overweight_Level_I       0.72      0.68      0.70      1942\n",
      "Overweight_Level_II       0.71      0.70      0.70      2018\n",
      "\n",
      "           accuracy                           0.86     16606\n",
      "          macro avg       0.84      0.84      0.84     16606\n",
      "       weighted avg       0.86      0.86      0.86     16606\n",
      "\n",
      "\n",
      "Validation Set Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.89      0.95      0.92       505\n",
      "      Normal_Weight       0.88      0.82      0.84       617\n",
      "     Obesity_Type_I       0.81      0.85      0.83       582\n",
      "    Obesity_Type_II       0.93      0.96      0.95       650\n",
      "   Obesity_Type_III       0.99      1.00      1.00       809\n",
      " Overweight_Level_I       0.75      0.71      0.73       485\n",
      "Overweight_Level_II       0.73      0.71      0.72       504\n",
      "\n",
      "           accuracy                           0.87      4152\n",
      "          macro avg       0.85      0.85      0.85      4152\n",
      "       weighted avg       0.87      0.87      0.87      4152\n",
      "\n",
      "Confusion Matrix (LogisticRegression):\n",
      "[[480  24   0   0   0   1   0]\n",
      " [ 59 504   2   0   0  42  10]\n",
      " [  1   0 492  36   5  11  37]\n",
      " [  0   0  21 626   0   0   3]\n",
      " [  0   0   0   1 807   1   0]\n",
      " [  1  45  15   0   0 342  82]\n",
      " [  0   3  78   9   0  58 356]]\n",
      "\n",
      "=== LDA ===\n",
      "Cross-validated Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.82      0.89      0.85      2018\n",
      "      Normal_Weight       0.76      0.72      0.74      2465\n",
      "     Obesity_Type_I       0.80      0.76      0.78      2328\n",
      "    Obesity_Type_II       0.91      0.96      0.93      2598\n",
      "   Obesity_Type_III       0.99      1.00      1.00      3237\n",
      " Overweight_Level_I       0.67      0.59      0.63      1942\n",
      "Overweight_Level_II       0.64      0.70      0.67      2018\n",
      "\n",
      "           accuracy                           0.82     16606\n",
      "          macro avg       0.80      0.80      0.80     16606\n",
      "       weighted avg       0.82      0.82      0.82     16606\n",
      "\n",
      "\n",
      "Validation Set Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.81      0.93      0.87       505\n",
      "      Normal_Weight       0.79      0.72      0.75       617\n",
      "     Obesity_Type_I       0.78      0.78      0.78       582\n",
      "    Obesity_Type_II       0.91      0.94      0.93       650\n",
      "   Obesity_Type_III       0.99      1.00      0.99       809\n",
      " Overweight_Level_I       0.68      0.60      0.64       485\n",
      "Overweight_Level_II       0.66      0.68      0.67       504\n",
      "\n",
      "           accuracy                           0.82      4152\n",
      "          macro avg       0.80      0.81      0.80      4152\n",
      "       weighted avg       0.82      0.82      0.82      4152\n",
      "\n",
      "Confusion Matrix (LDA):\n",
      "[[470  33   0   0   0   1   1]\n",
      " [101 442   1   0   0  54  19]\n",
      " [  1   1 456  54   7  13  50]\n",
      " [  0   0  29 612   5   0   4]\n",
      " [  0   0   1   2 805   1   0]\n",
      " [  6  74  16   0   0 289 100]\n",
      " [  0   9  82   4   0  66 343]]\n",
      "\n",
      "=== NaiveBayes ===\n",
      "Cross-validated Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.55      0.74      0.63      2018\n",
      "      Normal_Weight       0.52      0.20      0.28      2465\n",
      "     Obesity_Type_I       0.37      0.40      0.38      2328\n",
      "    Obesity_Type_II       0.49      0.97      0.66      2598\n",
      "   Obesity_Type_III       0.96      1.00      0.98      3237\n",
      " Overweight_Level_I       0.61      0.25      0.36      1942\n",
      "Overweight_Level_II       0.50      0.29      0.37      2018\n",
      "\n",
      "           accuracy                           0.59     16606\n",
      "          macro avg       0.57      0.55      0.52     16606\n",
      "       weighted avg       0.59      0.59      0.55     16606\n",
      "\n",
      "\n",
      "Validation Set Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.56      0.75      0.64       505\n",
      "      Normal_Weight       0.49      0.20      0.28       617\n",
      "     Obesity_Type_I       0.38      0.42      0.40       582\n",
      "    Obesity_Type_II       0.50      0.96      0.66       650\n",
      "   Obesity_Type_III       0.96      1.00      0.98       809\n",
      " Overweight_Level_I       0.60      0.24      0.34       485\n",
      "Overweight_Level_II       0.51      0.30      0.38       504\n",
      "\n",
      "           accuracy                           0.59      4152\n",
      "          macro avg       0.57      0.55      0.52      4152\n",
      "       weighted avg       0.59      0.59      0.55      4152\n",
      "\n",
      "Confusion Matrix (NaiveBayes):\n",
      "[[377  25  92   1   2   5   3]\n",
      " [257 123  98  45  17  37  40]\n",
      " [  1  17 243 271   5   9  36]\n",
      " [  0   2   5 624   0   3  16]\n",
      " [  0   1   0   1 806   1   0]\n",
      " [ 42  53 117  99   9 114  51]\n",
      " [  2  29  87 213   1  22 150]]\n",
      "\n",
      "=== SVM ===\n",
      "Cross-validated Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.88      0.94      0.91      2018\n",
      "      Normal_Weight       0.86      0.82      0.84      2465\n",
      "     Obesity_Type_I       0.83      0.83      0.83      2328\n",
      "    Obesity_Type_II       0.94      0.96      0.95      2598\n",
      "   Obesity_Type_III       1.00      1.00      1.00      3237\n",
      " Overweight_Level_I       0.74      0.71      0.72      1942\n",
      "Overweight_Level_II       0.72      0.73      0.72      2018\n",
      "\n",
      "           accuracy                           0.87     16606\n",
      "          macro avg       0.85      0.85      0.85     16606\n",
      "       weighted avg       0.87      0.87      0.87     16606\n",
      "\n",
      "\n",
      "Validation Set Performance:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.89      0.95      0.92       505\n",
      "      Normal_Weight       0.88      0.81      0.84       617\n",
      "     Obesity_Type_I       0.82      0.85      0.83       582\n",
      "    Obesity_Type_II       0.94      0.97      0.95       650\n",
      "   Obesity_Type_III       1.00      1.00      1.00       809\n",
      " Overweight_Level_I       0.76      0.73      0.74       485\n",
      "Overweight_Level_II       0.74      0.73      0.73       504\n",
      "\n",
      "           accuracy                           0.87      4152\n",
      "          macro avg       0.86      0.86      0.86      4152\n",
      "       weighted avg       0.87      0.87      0.87      4152\n",
      "\n",
      "Confusion Matrix (SVM):\n",
      "[[482  22   0   0   0   1   0]\n",
      " [ 58 502   1   0   0  48   8]\n",
      " [  1   0 495  32   2  10  42]\n",
      " [  0   0  22 628   0   0   0]\n",
      " [  0   0   2   1 806   0   0]\n",
      " [  1  42  13   0   0 352  77]\n",
      " [  0   6  72   7   0  53 366]]\n"
     ]
    }
   ],
   "source": [
    "# Obesity Risk Prediction with Validation & Reproducibility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ========================\n",
    "# 1. Initial Setup\n",
    "# ========================\n",
    "# Set global random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# ========================\n",
    "# 2. Data Checks\n",
    "# ========================\n",
    "# Check for missing values\n",
    "print(\"Missing values in train:\", train.isnull().sum().sum())\n",
    "print(\"Missing values in test:\", test.isnull().sum().sum())\n",
    "\n",
    "# Check basic data stats\n",
    "print(\"\\nTrain data description:\")\n",
    "print(train.describe(include='all'))\n",
    "\n",
    "# ========================\n",
    "# 3. Data Preparation\n",
    "# ========================\n",
    "# Train-validation split (80-20)\n",
    "X = train.drop(['id', 'NObeyesdad'], axis=1)\n",
    "y = train['NObeyesdad']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# 4. Preprocessing\n",
    "# ========================\n",
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', \n",
    "                       'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# 5. Model Setup\n",
    "# ========================\n",
    "models = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('model', LogisticRegression(max_iter=2000, random_state=RANDOM_SEED))\n",
    "    ]),\n",
    "    'LDA': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearDiscriminantAnalysis())\n",
    "    ]),\n",
    "    'NaiveBayes': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GaussianNB())\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(kernel='linear', random_state=RANDOM_SEED))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# 6. Model Evaluation\n",
    "# ========================\n",
    "for name, pipeline in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    \n",
    "    # Cross-validated predictions\n",
    "    y_pred = cross_val_predict(pipeline, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Validation metrics\n",
    "    print(\"Cross-validated Performance:\")\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    \n",
    "    # Final validation set evaluation\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    val_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    print(classification_report(y_val, val_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(f\"Confusion Matrix ({name}):\")\n",
    "    print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "# ========================\n",
    "# 7. Generate Submissions\n",
    "# ========================\n",
    "for name, pipeline in models.items():\n",
    "    pipeline.fit(X, y)  # Retrain on full data\n",
    "    test_pred = pipeline.predict(test.drop('id', axis=1))\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        'id': test['id'],\n",
    "        'NObeyesdad': test_pred\n",
    "    }).to_csv(f'submission_{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79698561-9e78-4e58-bec7-ff3ca1d51747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
